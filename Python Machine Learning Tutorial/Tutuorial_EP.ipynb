{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1d4b7f-865d-424c-92cc-355de26af047",
   "metadata": {},
   "source": [
    "Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "648524a2-afd4-49cb-a672-75452a01e569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\python39\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python39\\lib\\site-packages (from scikit-learn) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\python39\\lib\\site-packages (from scikit-learn) (1.21.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\python39\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\python39\\lib\\site-packages (from scikit-learn) (1.7.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Install scikit-learn\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7ff37185-d88c-46c0-851a-515a8079b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "#Create classes to be used\n",
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: #Score of 4 or 5\n",
    "            return Sentiment.POSITIVE\n",
    "\n",
    "class ReviewContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "        \n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "        \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "        positive_shrunk = positive[:len(negative)]\n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle(self.reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb87908-9b1c-484a-97b2-eecb1f04fe18",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9203c7c2-8754-4fe5-9634-9a89ccba5d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I hoped for Mia to have some peace in this book, but her story is so real and raw.  Broken World was so touching and emotional because you go from Mia\\'s trauma to her trying to cope.  I love the way the story displays how there is no \"just bouncing back\" from being sexually assaulted.  Mia showed us how those demons come for you every day and how sometimes they best you. I was so in the moment with Broken World and hurt with Mia because she was surrounded by people but so alone and I understood her feelings.  I found myself wishing I could give her some of my courage and strength or even just to be there for her.  Thank you Lizzy for putting a great character\\'s voice on a strong subject and making it so that other peoples story may be heard through Mia\\'s.'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create variable for the data to load\n",
    "file_name = './data/sentiment/books_small_10000.json'\n",
    "\n",
    "# Create empty list and append the data from the file\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))\n",
    "        \n",
    "reviews[5].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19781ec3-69ea-4ae6-8a3d-ed1a705554f5",
   "metadata": {},
   "source": [
    "Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4c30eee5-d8f8-41d5-b8bb-b89db92fb531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many rows\n",
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d227a726-279f-4473-a455-ce106f3ce1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train-Test Data\n",
    "# Training is the X and test is the y variables\n",
    "training, test = train_test_split(reviews, test_size=0.33, random_state=42)\n",
    "\n",
    "train_container = ReviewContainer(training)\n",
    "\n",
    "test_container = ReviewContainer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f71bc868-19eb-40e2-8631-1094f4ff7a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6700"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many rows after split\n",
    "len(training)\n",
    "#len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3257d231-7b21-431f-a12f-3498bd73afcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olivia Hampton arrives at the Dunraven family home as cataloger of their extensive library. What she doesn't expect is a broken carriage wheel on the way. Nor a young girl whose mind is clearly gone, an old man in need of care himself (and doesn&#8217;t quite seem all there in Olivia&#8217;s opinion). Furthermore, Marion Dunraven, the only sane one of the bunch and the one Olivia is inexplicable drawn to, seems captive to everyone in the dusty old house. More importantly, she doesn't expect to fall in love with Dunraven's daughter Marion.Can Olivia truly believe the stories of sadness and death that surround the house, or are they all just local neighborhood rumor?Was that carriage trouble just a coincidence or a supernatural sign to stay away? If she remains, will the Castle&#8217;s dark shadows take Olivia down with them or will she and Marion long enough to declare their love?Patty G. Henderson has created an atmospheric and intriguing story in her Gothic tale. I found this to be an enjoyable read, even if it isn&#8217;t my usual preferred genre. I think, with this tale, I got hooked on the old Gothic romantic style. So I think fans of the genre (and of lesbian romances) will enjoy it.\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "# display first text\n",
    "print(training[0].text)\n",
    "# display first sentiment\n",
    "print(training[0].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1904309b-7807-425c-8473-9a7c1b6a0959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More and more Wolfe seems derivative, or perhaps he was all along.  \"I Am Charlotte Simmons\" reads like he thought he could out-JC-Oates JC Oates.  Yet it lacks the soul of the female lead that JCO renders in such vivid hues (for example, Anellia in \"I'll Take You There\").Now \"Back to Blood\" would seem to be Wolfe's riff on Carl Hiaasen.  He must have thought he could do it better.  But Wolfe does not come close to the Miami Herald reporter's assiduously plotted romps through the land- and cityscape of rogues, crooked politicos and good (if unbalanced) guys who hunger for justice.Where Hiaasen's work rarely contains a wasted word, let alone plot twist, Wolfe delivers Miami's elite and vile mixing it up in a rambling foray some 700 pages long (I hope Little, Brown recouped their $10,000 per page investment).  The story is told primarily through the eyes of two Cubanos desperate to escape their home town Haileah, though for different reasons. It is punctuated with many lurid sex scenes including repeated references to one character's Herpes pustule-covered member.  (One visual of that will suffice.)  A late Act II's scene in a strip club does nothing to advance the plot or further character development, nor does the next sequence, a belabored slog through a senior housing complex where a Vodka-soaked Russian art forger hides from harm.  This was the juncture at which it seemed wise to skitter through the last 250 pages to learn the outcome.  A multitude of subplots and characters were abruptly dropped.Wolfe's novel contains its share of clever moments, but even the trenchant satire is so overwritten that the juiciest passages wear themselves thin.  This author's role in the development of \"New Journalism\" is undeniable.  He has my admiration for his thorough research into his subject matter; in fact, the authentic feel of Cuban-American culture may stem from as far back as his early stint with the Washington Post when he reported briefly from that country.  But in this as in other novels, Wolfe fails to write a single primary character that is not obsessed with how he or she is perceived by others.If readers are looking for a beautifully crafted novel that whirls around a crystalline perspective, this story will not satisfy, and it affirms Wolfe's place somewhere below the top tier of American authors.  If he is determined to out-write one of our best-known novelists, he may do well to pick one who possesses more middling talent.\n",
      "NEGATIVE\n",
      "436\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "# Training variables\n",
    "train_container.evenly_distribute()\n",
    "train_x = train_container.get_text()\n",
    "train_y = train_container.get_sentiment()\n",
    "# Display results\n",
    "print(train_x[0])\n",
    "print(train_y[0])\n",
    "\n",
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "87d9e9f3-f40e-4330-8cf7-911e6e25d4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard to put this book down. I found I really cared about the characters and was drawn into the story.\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "# Test variables\n",
    "test_container.evenly_distribute()\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "# Display results\n",
    "print(test_x[0])\n",
    "print(test_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c04665-d49a-497d-ab86-ef5bf198c886",
   "metadata": {},
   "source": [
    "Bags of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "830b3b6a-dfff-44e1-b021-85f2abeabbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More and more Wolfe seems derivative, or perhaps he was all along.  \"I Am Charlotte Simmons\" reads like he thought he could out-JC-Oates JC Oates.  Yet it lacks the soul of the female lead that JCO renders in such vivid hues (for example, Anellia in \"I'll Take You There\").Now \"Back to Blood\" would seem to be Wolfe's riff on Carl Hiaasen.  He must have thought he could do it better.  But Wolfe does not come close to the Miami Herald reporter's assiduously plotted romps through the land- and cityscape of rogues, crooked politicos and good (if unbalanced) guys who hunger for justice.Where Hiaasen's work rarely contains a wasted word, let alone plot twist, Wolfe delivers Miami's elite and vile mixing it up in a rambling foray some 700 pages long (I hope Little, Brown recouped their $10,000 per page investment).  The story is told primarily through the eyes of two Cubanos desperate to escape their home town Haileah, though for different reasons. It is punctuated with many lurid sex scenes including repeated references to one character's Herpes pustule-covered member.  (One visual of that will suffice.)  A late Act II's scene in a strip club does nothing to advance the plot or further character development, nor does the next sequence, a belabored slog through a senior housing complex where a Vodka-soaked Russian art forger hides from harm.  This was the juncture at which it seemed wise to skitter through the last 250 pages to learn the outcome.  A multitude of subplots and characters were abruptly dropped.Wolfe's novel contains its share of clever moments, but even the trenchant satire is so overwritten that the juiciest passages wear themselves thin.  This author's role in the development of \"New Journalism\" is undeniable.  He has my admiration for his thorough research into his subject matter; in fact, the authentic feel of Cuban-American culture may stem from as far back as his early stint with the Washington Post when he reported briefly from that country.  But in this as in other novels, Wolfe fails to write a single primary character that is not obsessed with how he or she is perceived by others.If readers are looking for a beautifully crafted novel that whirls around a crystalline perspective, this story will not satisfy, and it affirms Wolfe's place somewhere below the top tier of American authors.  If he is determined to out-write one of our best-known novelists, he may do well to pick one who possesses more middling talent.\n",
      "  (0, 7779)\t0.05094921779344689\n",
      "  (0, 5074)\t0.058524765690058274\n",
      "  (0, 6014)\t0.058524765690058274\n",
      "  (0, 5860)\t0.041866303688675444\n",
      "  (0, 8665)\t0.02339980144553201\n",
      "  (0, 5421)\t0.058524765690058274\n",
      "  (0, 4502)\t0.041866303688675444\n",
      "  (0, 862)\t0.030685227479356623\n",
      "  (0, 5587)\t0.03191230838116717\n",
      "  (0, 2187)\t0.04608961823834954\n",
      "  (0, 661)\t0.041866303688675444\n",
      "  (0, 8028)\t0.058524765690058274\n",
      "  (0, 8083)\t0.04083150179517695\n",
      "  (0, 848)\t0.058524765690058274\n",
      "  (0, 7315)\t0.05094921779344689\n",
      "  (0, 5900)\t0.03613562293084127\n",
      "  (0, 275)\t0.058524765690058274\n",
      "  (0, 6865)\t0.05279408493222411\n",
      "  (0, 5823)\t0.04706340417438995\n",
      "  (0, 1897)\t0.058524765690058274\n",
      "  (0, 544)\t0.032783389583903984\n",
      "  (0, 8698)\t0.058524765690058274\n",
      "  (0, 1822)\t0.058524765690058274\n",
      "  (0, 792)\t0.04706340417438995\n",
      "  (0, 4758)\t0.03315925543120739\n",
      "  :\t:\n",
      "  (0, 7929)\t0.16802229025511822\n",
      "  (0, 4523)\t0.05279408493222411\n",
      "  (0, 4277)\t0.07216499751031488\n",
      "  (0, 8872)\t0.03191230838116717\n",
      "  (0, 5446)\t0.11704953138011655\n",
      "  (0, 4335)\t0.11704953138011655\n",
      "  (0, 5589)\t0.044695297623501856\n",
      "  (0, 1790)\t0.047772545234969585\n",
      "  (0, 7987)\t0.05974272380177489\n",
      "  (0, 4684)\t0.02000829189783918\n",
      "  (0, 6400)\t0.042436710857811734\n",
      "  (0, 7155)\t0.058524765690058274\n",
      "  (0, 1368)\t0.058524765690058274\n",
      "  (0, 387)\t0.027145085482189878\n",
      "  (0, 371)\t0.03560204265872161\n",
      "  (0, 347)\t0.02004756809859472\n",
      "  (0, 8608)\t0.028555222280010024\n",
      "  (0, 3677)\t0.23340956893131776\n",
      "  (0, 5802)\t0.03869986748009042\n",
      "  (0, 5549)\t0.06612421643612272\n",
      "  (0, 2137)\t0.05517253234312099\n",
      "  (0, 6963)\t0.03534763413315312\n",
      "  (0, 8774)\t0.4096733598304079\n",
      "  (0, 423)\t0.06273429861930316\n",
      "  (0, 5185)\t0.06049958633970879\n"
     ]
    }
   ],
   "source": [
    "# Create Count Vector for train data\n",
    "\n",
    "# This book is great !\n",
    "# This book was so bad\n",
    "\n",
    "#vectorizer = CountVectorizer() # Not optimized\n",
    "vectorizer = TfidfVectorizer() # Optimized by word frequency\n",
    "train_x_vectors = vectorizer.fit_transform(train_x) # vectorizes the taining data\n",
    "# The above line does the fit and transform in one line\n",
    "# above line could also be split out by doing the following two lines\n",
    "# vectorizer.fit(train_x)\n",
    "# train_x_vectors = vectorizer.transform(train_x)\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "print(train_x[0])\n",
    "print(train_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e81ae0-2f2b-4dd9-aaa0-7c92bb0cd34e",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf72c561-610a-41c3-b8a5-c7b1df8e51c4",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a31d2032-4c36-4062-ac18-f910daa87a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import svm library\n",
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    "test_x[0]\n",
    "\n",
    "clf_svm.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c3130-6095-418e-a9fc-66695620d787",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "18eeb84b-1e9e-4e05-8097-9cd337018492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Library\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_dec.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d281e97-2079-4af7-aa7c-8e7fc6dce266",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "75d10532-3871-4b1d-b380-7cd0a40e43f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_256/1234325616.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf_gnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mclf_gnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mclf_gnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x_vectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python39\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    243\u001b[0m         \"\"\"\n\u001b[0;32m    244\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         return self._partial_fit(\n\u001b[0m\u001b[0;32m    246\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_refit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         )\n",
      "\u001b[1;32mC:\\python39\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_partial_fit_first_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfirst_call\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python39\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    718\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m         array = _ensure_sparse_format(\n\u001b[0m\u001b[0;32m    721\u001b[0m             \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m         raise TypeError(\n\u001b[0m\u001b[0;32m    441\u001b[0m             \u001b[1;34m\"A sparse matrix was passed, but dense \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[1;34m\"data is required. Use X.toarray() to \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "# Import Library\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_gnb.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a5339-ab7e-45b4-ac4c-51b435585d0c",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d350a0c7-36d8-4412-ae85-88682e9064ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_log.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0dd912-ecb2-4d14-be04-f66d0ccf5283",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bd7cb7f6-c2c0-48c1-a27c-2280e4c400dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8076923076923077\n",
      "0.6947115384615384\n",
      "0.8052884615384616\n"
     ]
    }
   ],
   "source": [
    "# Compare results to confirm accuracy\n",
    "# Mean Accuracy\n",
    "print(clf_svm.score(test_x_vectors, test_y)) # Linear SVM\n",
    "print(clf_dec.score(test_x_vectors, test_y)) # Decision Tree\n",
    "print(clf_log.score(test_x_vectors, test_y)) # Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1884fff1-8eb7-4dcb-aeb6-87c56c2c867b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80582524 0.80952381]\n",
      "[0.69099757 0.69833729]\n",
      "[0.80291971 0.80760095]\n"
     ]
    }
   ],
   "source": [
    "# F1 Score\n",
    "# Import Library\n",
    "from sklearn.metrics import f1_score\n",
    "# Linear SVM, Decision Tree, Logistic Regression\n",
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_dec.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_log.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "83332b7c-9e99-4802-9609-1782c4eded8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at train data as the values for Neutral and Negative are way off\n",
    "train_y.count(Sentiment.POSITIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7ace603c-5625-43d2-b842-a8fd4ab9c681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'NEGATIVE', 'NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the quality using the Linear SVM model\n",
    "test_set = ['very fun', \"bad book do not buy\", 'horrible waste of time']\n",
    "new_test = vectorizer.transform(test_set)\n",
    "\n",
    "clf_svm.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "72e7e8c7-da8d-4d7e-8de7-f40408ba72ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'NEGATIVE', 'POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the quality using the Decision Tree model\n",
    "test_set = ['not great', \"bad book do not buy\", 'horrible waste of time']\n",
    "new_test = vectorizer.transform(test_set)\n",
    "\n",
    "clf_dec.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fbb455f2-085d-4c60-8561-1d9c7ebd1002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'POSITIVE', 'NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the quality using the Logistic Regression model\n",
    "test_set = ['very fun', \"great book to buy\", 'horrible waste of time']\n",
    "new_test = vectorizer.transform(test_set)\n",
    "\n",
    "clf_log.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac399f1b-af74-4471-8a70-207b70bb5942",
   "metadata": {},
   "source": [
    "#### Tuning our model (with Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c7c83471-6f03-40e0-a8d5-7a9438df7066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': (1, 4, 8, 16, 32), 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel': ('linear', 'rbf'), 'C': (1,4,8,16,32)}\n",
    "\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dc2a6ac4-c745-498f-98f1-54685c65e843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8076923076923077\n",
      "0.6947115384615384\n",
      "0.8052884615384616\n",
      "0.8197115384615384\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy\n",
    "print(clf_svm.score(test_x_vectors, test_y)) # Linear SVM\n",
    "print(clf_dec.score(test_x_vectors, test_y)) # Decision Tree\n",
    "print(clf_log.score(test_x_vectors, test_y)) # Logistic Regression\n",
    "print(clf.score(test_x_vectors, test_y)) # Tuned model w/ GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c0e740-618e-414b-885b-0e9525eb6d2e",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "274457f4-e462-4a69-985b-b32f140c0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import pickle\n",
    "\n",
    "with open('./models/sentiment_classifier_EP.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "    \n",
    "# Save Vectorizer\n",
    "with open('./models/sentiment_vectorizer_EP.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6663267-b967-45cc-9076-15476b3ca7ae",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ca843687-068d-450c-87af-3084be175c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models/sentiment_classifier_EP.pkl', 'rb') as f:\n",
    "    loaded_clf = pickle.load(f)\n",
    "\n",
    "# Load Vectorizer\n",
    "with open('./models/sentiment_vectorizer_EP.pkl', 'rb') as f:\n",
    "    vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "98390946-d3cc-4650-a6c6-fabd6e66d09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard to put this book down. I found I really cared about the characters and was drawn into the story.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_x[0])\n",
    "\n",
    "loaded_clf.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d58b5-6221-47cc-9643-1654df22ce8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
